{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQLk-F1gwxrf",
        "outputId": "4717c876-869d-46d5-87b5-384cbac49203"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def clean_and_process_data(input_file, output_file):\n",
        "    print(f\"Loading data from {input_file}...\")\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(input_file, low_memory=False)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{input_file}' was not found.\")\n",
        "        print(\"Please make sure the CSV file is in the same folder as this script.\")\n",
        "        return\n",
        "\n",
        "    # 1. Drop unnecessary PII and administrative columns\n",
        "    # We remove high-cardinality text (Job Title, Skills) that requires NLP, keeping structured data.\n",
        "    cols_to_drop = [\n",
        "        'EMP_CONTACT_NAME', 'EMP_CONTACT_CITY', 'EMP_CONTACT_STATE_PROVINCE',\n",
        "        'SPECIFIC_SKILLS', 'EMPLOYER_NAME', 'EMPLOYER_CITY', 'WORKSITE_CITY',\n",
        "        'JOB_TITLE', 'MAJOR_FIELD_OF_STUDY', 'CASE_NUMBER'\n",
        "    ]\n",
        "    df_clean = df.drop(columns=cols_to_drop, errors='ignore')\n",
        "\n",
        "    # 2. Date Conversion\n",
        "    print(\"Processing dates...\")\n",
        "    df_clean['RECEIVED_DATE'] = pd.to_datetime(df_clean['RECEIVED_DATE'], errors='coerce')\n",
        "    df_clean['DECISION_DATE'] = pd.to_datetime(df_clean['DECISION_DATE'], errors='coerce')\n",
        "\n",
        "    # Drop rows where critical dates are missing\n",
        "    df_clean = df_clean.dropna(subset=['RECEIVED_DATE', 'DECISION_DATE'])\n",
        "\n",
        "    # 3. Calculate Target Variable: Processing Time (Days)\n",
        "    df_clean['PROCESSING_TIME_DAYS'] = (df_clean['DECISION_DATE'] - df_clean['RECEIVED_DATE']).dt.days\n",
        "\n",
        "    # Remove negative processing times (data errors)\n",
        "    df_clean = df_clean[df_clean['PROCESSING_TIME_DAYS'] >= 0]\n",
        "\n",
        "    # 4. Clean Wage Data\n",
        "    print(\"Cleaning wage data...\")\n",
        "    def clean_wage(wage):\n",
        "        if pd.isna(wage):\n",
        "            return np.nan\n",
        "        if isinstance(wage, str):\n",
        "            clean_str = wage.replace('$', '').replace(',', '').strip()\n",
        "            try:\n",
        "                return float(clean_str)\n",
        "            except ValueError:\n",
        "                return np.nan\n",
        "        return float(wage)\n",
        "\n",
        "    df_clean['PW_WAGE'] = df_clean['PW_WAGE'].apply(clean_wage)\n",
        "\n",
        "    # 5. Handle Missing Values (Imputation)\n",
        "    fill_values = {\n",
        "        'PW_SKILL_LEVEL': 'Unknown',\n",
        "        'MINIMUM_EDUCATION': 'Unknown',\n",
        "        'PW_SOC_TITLE': 'Unknown',\n",
        "        'WORKSITE_STATE': 'Unknown',\n",
        "        'EMPLOYER_STATE_PROVINCE': 'Unknown'\n",
        "    }\n",
        "    df_clean = df_clean.fillna(value=fill_values)\n",
        "\n",
        "    # 6. Feature Engineering\n",
        "    print(\"Engineering features...\")\n",
        "    # Seasonality\n",
        "    df_clean['SUBMISSION_MONTH'] = df_clean['RECEIVED_DATE'].dt.month\n",
        "    df_clean['SUBMISSION_YEAR'] = df_clean['RECEIVED_DATE'].dt.year\n",
        "\n",
        "    # Job Category Grouping (First 2 digits of SOC code)\n",
        "    df_clean['SOC_MAJOR_GROUP'] = df_clean['PW_SOC_CODE'].astype(str).str[:2]\n",
        "\n",
        "    # 7. Final Column Selection\n",
        "    # We remove DECISION_DATE to prevent data leakage in the model\n",
        "    final_cols = [\n",
        "        'RECEIVED_DATE',\n",
        "        'EMPLOYER_STATE_PROVINCE',\n",
        "        'PW_SOC_CODE',\n",
        "        'PW_SOC_TITLE',\n",
        "        'SOC_MAJOR_GROUP',\n",
        "        'PW_SKILL_LEVEL',\n",
        "        'PW_WAGE',\n",
        "        'WORKSITE_STATE',\n",
        "        'MINIMUM_EDUCATION',\n",
        "        'SUBMISSION_MONTH',\n",
        "        'SUBMISSION_YEAR',\n",
        "        'CASE_STATUS',          # Target for Classification\n",
        "        'PROCESSING_TIME_DAYS'  # Target for Regression\n",
        "    ]\n",
        "\n",
        "    # Ensure all columns exist\n",
        "    available_cols = [c for c in final_cols if c in df_clean.columns]\n",
        "    df_final = df_clean[available_cols]\n",
        "\n",
        "    # 8. Save Output\n",
        "    print(f\"Saving processed data to {output_file}...\")\n",
        "    df_final.to_csv(output_file, index=False)\n",
        "    print(\"Success! Data processing complete.\")\n",
        "    print(f\"Rows processed: {len(df_final)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Updated input path as requested\n",
        "    input_csv = '/content/drive/MyDrive/Datasets/PERM_Disclosure_Data_FY2025_Q3_Final.csv'\n",
        "    output_csv = 'Processed_Visa_Dataset.csv'\n",
        "\n",
        "    clean_and_process_data(input_csv, output_csv)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from /content/drive/MyDrive/Datasets/PERM_Disclosure_Data_FY2025_Q3_Final.csv...\n",
            "Processing dates...\n",
            "Cleaning wage data...\n",
            "Engineering features...\n",
            "Saving processed data to Processed_Visa_Dataset.csv...\n",
            "Success! Data processing complete.\n",
            "Rows processed: 1171\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l54eYz_KwK4Z",
        "outputId": "b9bf0683-a89e-48d3-c58c-01c81ba3d332"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Define the file path\n",
        "file_path = 'Processed_Visa_Dataset.csv'\n",
        "\n",
        "# Check if the file exists to prevent errors, then download\n",
        "if os.path.exists(file_path):\n",
        "    print(f\"Found {file_path}. Starting download...\")\n",
        "    files.download(file_path)\n",
        "else:\n",
        "    print(f\"Error: {file_path} not found. Please ensure the processing script finished successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "O9GTvQgmx6w9",
        "outputId": "75bf289f-7a49-4b2d-b347-c6895ce1797c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found Processed_Visa_Dataset.csv. Starting download...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4705837a-7ddd-4941-a694-02b1aeb656d4\", \"Processed_Visa_Dataset.csv\", 135895)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Load the processed CSV file\n",
        "output_csv = 'Processed_Visa_Dataset.csv'\n",
        "df_processed = pd.read_csv(output_csv)\n",
        "\n",
        "# Display dataset dimensions\n",
        "print(f\"Dataset Shape: {df_processed.shape}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Display the first 5 rows\n",
        "print(\"First 5 rows of the processed dataset:\")\n",
        "# In Jupyter/Colab, simply typing the dataframe variable at the end displays it nicely\n",
        "# If you are using a script, use print(df_processed.head())\n",
        "print(df_processed.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcBP4e6OBqNc",
        "outputId": "aba921a7-0811-4511-e5e0-b28c8b2fa5cd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape: (1171, 13)\n",
            "------------------------------\n",
            "First 5 rows of the processed dataset:\n",
            "  RECEIVED_DATE EMPLOYER_STATE_PROVINCE PW_SOC_CODE  \\\n",
            "0    2023-02-27                ILLINOIS  25-1067.00   \n",
            "1    2022-10-03          NORTH CAROLINA     11-3031   \n",
            "2    2022-07-22          CONNECTICUT CT     11-9051   \n",
            "3    2022-06-20                 FLORIDA     11-9013   \n",
            "4    2022-09-30                 GEORGIA     11-9021   \n",
            "\n",
            "                        PW_SOC_TITLE SOC_MAJOR_GROUP PW_SKILL_LEVEL   PW_WAGE  \\\n",
            "0  Sociology Teachers, Postsecondary              25        Level I   44490.0   \n",
            "1                 Financial Managers              11        Level I  125986.0   \n",
            "2              Food Service Managers              11       Level IV  119434.0   \n",
            "3              Regional Farm Manager              11       Level IV  161866.0   \n",
            "4              Construction Managers              11       Level II   83762.0   \n",
            "\n",
            "  WORKSITE_STATE MINIMUM_EDUCATION  SUBMISSION_MONTH  SUBMISSION_YEAR  \\\n",
            "0       ILLINOIS         Doctorate                 2             2023   \n",
            "1       NEW YORK        Bachelor's                10             2022   \n",
            "2    CONNECTICUT       High School                 7             2022   \n",
            "3        FLORIDA        Bachelor's                 6             2022   \n",
            "4        GEORGIA           Unknown                 9             2022   \n",
            "\n",
            "  CASE_STATUS  PROCESSING_TIME_DAYS  \n",
            "0      Denied                   582  \n",
            "1      Denied                   730  \n",
            "2      Denied                   803  \n",
            "3      Denied                   835  \n",
            "4      Denied                   733  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}